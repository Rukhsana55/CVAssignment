{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'flower_photos/'\n",
    "classes_dir = ['daisy','dandelion','roses', 'sunflowers', 'tulips']\n",
    "\n",
    "test_ratio = 0.20\n",
    "for classes in classes_dir:\n",
    "    os.makedirs(root_dir +'train\\\\' + classes)\n",
    "    os.makedirs(root_dir +'test\\\\' + classes)\n",
    "    src = root_dir + classes\n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),[int(len(allFileNames)* (1 - test_ratio))])\n",
    "    train_FileNames = [src+'\\\\'+ name for name in train_FileNames.tolist()]\n",
    "    test_FileNames = [src+'\\\\' + name for name in test_FileNames.tolist()]\n",
    "    print('Total images: ', len(allFileNames))\n",
    "    print('Training: ', len(train_FileNames))\n",
    "    print('Testing: ', len(test_FileNames))\n",
    "    print(\"***********\")\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, root_dir +'train\\\\' + cls)\n",
    "    for name in test_FileNames:\n",
    "        shutil.copy(name, root_dir +'test\\\\' + cls)\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    io.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(train, path):\n",
    "    images = []\n",
    "    count = 0\n",
    "    for folder in os.listdir(path):\n",
    "        for file in  os.listdir(os.path.join(path, folder)):\n",
    "            images.append(os.path.join(path, os.path.join(folder, file)))\n",
    "\n",
    "    if(train is True):\n",
    "        np.random.shuffle(images)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def getDescriptors(sift, img):\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des\n",
    "\n",
    "def readImage(img_path):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    return cv2.resize(img,(150,150))\n",
    "\n",
    "def vstackDescriptors(descriptor_list):\n",
    "    descriptors = np.array(descriptor_list[0])\n",
    "    for descriptor in descriptor_list[1:]:\n",
    "        descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "    return descriptors\n",
    "\n",
    "def clusterDescriptors(descriptors, no_clusters):\n",
    "    kmeans = KMeans(n_clusters = no_clusters).fit(descriptors)\n",
    "    return kmeans\n",
    "\n",
    "def extractFeatures(kmeans, descriptor_list, image_count, no_clusters):\n",
    "    im_features = np.array([np.zeros(no_clusters) for i in range(image_count)])\n",
    "    for i in range(image_count):\n",
    "        for j in range(len(descriptor_list[i])):\n",
    "            feature = descriptor_list[i][j]\n",
    "            feature = feature.reshape(1, 128)\n",
    "            idx = kmeans.predict(feature)\n",
    "            im_features[i][idx] += 1\n",
    "\n",
    "    return im_features\n",
    "\n",
    "def normalizeFeatures(scale, features):\n",
    "    return scale.transform(features)\n",
    "\n",
    "def plotHistogram(im_features, no_clusters):\n",
    "    x_scalar = np.arange(no_clusters)\n",
    "    y_scalar = np.array([abs(np.sum(im_features[:,h], dtype=np.int32)) for h in range(no_clusters)])\n",
    "\n",
    "    plt.bar(x_scalar, y_scalar)\n",
    "    plt.xlabel(\"Visual Word Index\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Complete Vocabulary Generated\")\n",
    "    plt.xticks(x_scalar + 0.4, x_scalar)\n",
    "    plt.show()\n",
    "\n",
    "def svcParamSelection(X, y, kernel, nfolds):\n",
    "#     labels = np.unique(y)\n",
    "#     print(labels)\n",
    "    Cs = [0.5, 0.1, 0.15, 0.2, 0.3]\n",
    "    gammas = [0.1, 0.11, 0.095, 0.105]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def findSVM(im_features, train_labels, kernel):\n",
    "    features = im_features\n",
    "    if(kernel == \"precomputed\"):\n",
    "        features = np.dot(im_features, im_features.T)\n",
    "    \n",
    "    params = svcParamSelection(features, train_labels, kernel, 5)\n",
    "    C_param, gamma_param = params.get(\"C\"), params.get(\"gamma\")\n",
    "    print(C_param, gamma_param)\n",
    "#     class_weight = {\n",
    "#         0: (2934 / (5 * 506)),\n",
    "#         1: (2934/ (5 * 718)),\n",
    "#         2: (2934 / (5 * 512)),\n",
    "#         3: (2934 / (5 * 559)),\n",
    "#         4: (2934 / (5 * 639)),\n",
    "#     }\n",
    "  \n",
    "    svm = SVC(kernel = kernel, C =  C_param, gamma = gamma_param)\n",
    "    svm.fit(features, train_labels)\n",
    "    return svm\n",
    "\n",
    "def plotConfusionMatrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plotConfusions(true, predictions):\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    class_names =['daisy','dandelion','roses', 'sunflowers', 'tulips']\n",
    "    plotConfusionMatrix(true, predictions, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "    plotConfusionMatrix(true, predictions, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def findAccuracy(true, predictions):\n",
    "    print ('accuracy score: %0.3f' % accuracy_score(true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(path, no_clusters, kernel):\n",
    "    images = getFiles(True, path)\n",
    "    print(\"Train images path detected.\")\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    descriptor_list = []\n",
    "    train_labels = np.array([])\n",
    "    label_count = 5\n",
    "    image_count = len(images)\n",
    "    #print(image_count)\n",
    "\n",
    "    for img_path in images:\n",
    "        \n",
    "        if(\"daisy\" in img_path):\n",
    "            class_index = 0\n",
    "        elif(\"dandelion\" in img_path):\n",
    "            class_index = 1\n",
    "        elif(\"roses\" in img_path):\n",
    "            class_index = 2\n",
    "        elif(\"sunflowers\" in img_path):\n",
    "            class_index = 3\n",
    "        else:\n",
    "            class_index = 4\n",
    "\n",
    "        train_labels = np.append(train_labels, class_index)\n",
    "        img = readImage(img_path)\n",
    "        des = getDescriptors(sift, img)\n",
    "        descriptor_list.append(des)\n",
    "\n",
    "    descriptors = vstackDescriptors(descriptor_list)\n",
    "    print(\"Descriptors vstacked.\")\n",
    "\n",
    "    kmeans = clusterDescriptors(descriptors, no_clusters)\n",
    "    print(\"Descriptors clustered.\")\n",
    "\n",
    "    im_features = extractFeatures(kmeans, descriptor_list, image_count, no_clusters)\n",
    "    print(\"Images features extracted.\")\n",
    "\n",
    "    scale = StandardScaler().fit(im_features)        \n",
    "    im_features = scale.transform(im_features)\n",
    "    print(\"Train images normalized.\")\n",
    "\n",
    "    plotHistogram(im_features, no_clusters)\n",
    "    print(\"Features histogram plotted.\")\n",
    "\n",
    "    svm = findSVM(im_features, train_labels, kernel)\n",
    "    print(\"SVM fitted.\")\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    return kmeans, scale, svm, im_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"flower_photos/train\"\n",
    "test_path = \"flower_photos/test\"\n",
    "no_clusters = 50\n",
    "kernel = \"precomputed\"\n",
    "\n",
    "start_time = time.time()\n",
    "kmeans, scale, svm, im_features = trainModel(train_path, no_clusters, kernel)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(path, kmeans, scale, svm, im_features, no_clusters, kernel):\n",
    "    test_images = getFiles(False, path)\n",
    "    print(\"Test images path detected.\")\n",
    "\n",
    "    count = 0\n",
    "    true = []\n",
    "    descriptor_list = []\n",
    "\n",
    "    name_dict =\t{\n",
    "        \"0\": \"daisy\",\n",
    "        \"1\": \"dandelion\",\n",
    "        \"2\": \"roses\",\n",
    "        \"3\": \"sunflowers\",\n",
    "        \"4\": \"tulips\"\n",
    "    }\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    for img_path in test_images:\n",
    "        img = readImage(img_path)\n",
    "        des = getDescriptors(sift, img)\n",
    "\n",
    "        if(des is not None):\n",
    "            count += 1\n",
    "            descriptor_list.append(des)\n",
    "\n",
    "            if(\"daisy\" in img_path):\n",
    "                true.append(\"daisy\")\n",
    "            elif(\"dandelion\" in img_path):\n",
    "                true.append(\"dandelion\")\n",
    "            elif(\"roses\" in img_path):\n",
    "                true.append(\"roses\")  \n",
    "            elif(\"sunflowers\" in img_path):\n",
    "                true.append(\"sunflowers\")\n",
    "            else:\n",
    "                true.append(\"tulips\")\n",
    "\n",
    "    descriptors = vstackDescriptors(descriptor_list)\n",
    "\n",
    "    test_features = extractFeatures(kmeans, descriptor_list, count, no_clusters)\n",
    "\n",
    "    test_features = scale.transform(test_features)\n",
    "    \n",
    "    kernel_test = test_features\n",
    "    if(kernel == \"precomputed\"):\n",
    "        kernel_test = np.dot(test_features, im_features.T)\n",
    "    \n",
    "    predictions = [name_dict[str(int(i))] for i in svm.predict(kernel_test)]\n",
    "    print(\"Test images classified.\")\n",
    "\n",
    "    plotConfusions(true, predictions)\n",
    "    print(\"Confusion matrixes plotted.\")\n",
    "\n",
    "    findAccuracy(true, predictions)\n",
    "    print(\"Accuracy calculated.\")\n",
    "    print(\"Execution done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "testModel(test_path, kmeans, scale, svm, im_features, no_clusters, kernel)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
